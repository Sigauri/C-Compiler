Lexical analyzer design

-What does it do? 

The lexer takes a set of characters from a file and forms a structure called "token".
The structure contains the type of the token and its lexeme. 

-How does it work ?

Before using any functions of the lexer, the user must call the initialization function,
which initializes standard search paths for header files, the lexer state etc.
The user gets tokens by calling get_next_token().


Types of constants:
-Integer
-Floating Point
-Character

Keywords and Identifiers 

Identifier and keywords consist of characters, digits and the underscore characters, but always start 
with a character.

How do we distinguish Keywords from Identifiers?





Reading Files

The lexer will read the file to be lexed with C standard lib functions 
and store data into a buffer. All dynamic memory allocation will be done with malloc.
A data structure containing infos about the file will be malloce'd for each
file that was opened.

Recognition and Handling of punctuators 

The full list of punctuators:
>-<+/*%!&|^#.=[](){},;:~

First 14 can be continued with multiple characters, for example:

>	>>	>>= >=


Infos to be associated with identifier

-First occurence
-its lexeme
-its type

Infos to be associated with keywords

-its type
-its lexeme

--DONE--

-Basic data structures
-Basic initialization
-Stack of header files

--TODO

-Handle comments
-Test input bufferisation
-Symbol table
-Directives handling
-Additive info for identifiers
-Define some macros for c_tok_type ??
-Comment everything.



Thoughts
Encoding 
Symbol table - global and local.
#include directive handling
Keep track of new line chars
Error handling? Warning messages? 
The interface for using the lexer ? 
Macros - FUCK YOU!!!


Main structures:

-Lexer state 

-Token

-The file structure

