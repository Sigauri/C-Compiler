Parser design

The main task of the parser is to build an intermediate representation of the program
based on stream of tokens it gets from the lexer and check if the program is syntactically correct.
If there is an error in syntax of a program, the parser should at least output an error message
with the number of the string where the error occured. Error handling will be described in more detail later.


The source code will be parsed using a recursive-descent method, wich means that the tree is built
from the root towards the leaves and input is scanned from left to right.  
There will be one function implementing each nonterminal. For the grammars to be suitable for our parser,
they must be left-factored and the left recursions must be eliminated. The parser looks one symbol ahead.
Before trying to code things, ambiguities in grammars, too, have to be dealt with.



Lets have a look at the grammar for arithmetic expressions.
First, i'll show you the "wrong" one, explain why its wrong,
and then we will write the "right" grammar.

E -> E + E | E - E | E * E | E / E | id

Here "id" stands for any set of characters and digits, beginning with a character.
A really simple grammar. Whats wrong about it? 
First of all - Left recursion(which can't be parsed by a recursive-descent parser).
Second - Ambiguity. The ambiguous grammars have more than one parse tree for a given string.

Here's an example: 

Let's say we have an expression a + b * c

How is that string derived from the grammar above?
The first option:

E -> E + E -> a + E -> a + E * E -> a + b * E -> a + b * c 

The second option:

E -> E * E -> E + E * E -> a + E * E -> a + b * E -> a + b * c 

So, both of these methods derive the same string a + b * c, but if we would
build a tree while parsing this string, and evaluate the values of these expressions, 
the first option would give us a + (b * c), which is, obiously, the right one, because
multiplication has higher precedence than adding, and the second one, would give us
(a + b) * c, which is wrong. So, in order for our parser to be able to parse the string correctly,
we need to rewrite this grammar.

Here's the "right" way of doing it:

E -> E + T | E - T | T

T -> * F | / F | F 

F -> id | e

Now, you can check that there is only one way of deriving the string a + b * c from this grammar.

Now that we have eliminated the ambiguity in the grammar, is it suitable for our parser? Not really.
The reason is the production  E -> E + T | E - T | T.
Because the leftmost symbol after the -> is equal to that of before ->, it is left recursive.
Luckily, left recursion is easy to eliminate.

E -> T E' | T E'

E' ->  + T E' | -T E' | e

T -> * F | / F | F 

F -> id | e

That's it. 

PS: I don't really understand the problem of ambiguous grammars good enough, so there is a good chance that
some of the things i wrote may be wrong. The example on ambiguity was taken from the dragon book.
I am planning to find out more about that and correct/add something to this.
But anyway, these are the problems of tomorrow me :)




While parsing the string, the parser also has to generate the intermediate representation of the program.
For now, i chose to generate the syntax tree. Three-address code and other intermediate representations can be
generated by traversing the syntax tree.

Here's a syntax tree for expression a + b * c

									   +
									   /\
									  /  \
									 a    *
									 	 / \
									 	/   \
									   b	 c



When trying to implement the parser, i confronted another problem.
Let's say we have a grammar of form
	
	L -> id | const
	M -> L | ++M
	G -> M | G++
	S -> G | M.

Suppose we have a string ++id++ which we want to parse from S.
First token we see is "++", but "++" is both in First(M) and in First(G)(Because G produces M).
We only have one symbol of lookahead, how do we choose which production to apply? 
There should be other, more powerful algorithms that would handle this problem efficiently,
but for now, to keep things simple i am going to do bactracking. 

Now, the longest production in S is "M.", so we try it first. The "++id" part of the string matches,
but then we have "++", which doesn't match with ".", so we have an error. Now we go back to the 
state before we tried to apply the production and try G. G fits for our string. Done.



-Error handling
Again, i chose the simplest way to go about it. I am going to handle Errors with a method called
Panic-Mode Recovery, described in the dragonbook(Yeh, almost all techniques that i use are taken from dragon book :) ).

Here's what the book says:
"With this method, on discovering an error, the parser discards input symbols
one at a time until one of a designated set of synchronizing tokens is found.
The synchronizing tokens are usually delimiters, such as semicolon or }, whose
role in the source program is clear and unambiguous. While panic-mode correction often skips a 
considerable amount of input without checking it for additional errors, it has the 
advantage of simplicity, and, unlike some methods to be considered later, is 
guaranteed not to go into an infinite loop."

Suppose we have the following grammar 
 
	E -> T E'

	E' ->  + T E' | -T E' | e

	T -> * F | / F | F 

	F -> id | e


We want to derive a string "id . id" from E. "id" is derived as follows: E->T->F->id.
Next we have ".". We look in FIRST(E') - no matches. So, we would output an error here of form
"Epected operator in line line_num" and skip all the tokens till we meet one of the synchronizing tokens.

But there is a little catch here - Backtracking. Let's take the above grammar again.
	
	L -> id | const
	M -> L | ++M
	G -> M | G++
	S -> G | M.

We want to derive the same string from it: "++id++". We store the current state and try to apply the production "M."
We derive "++id" from M, after that the lookahead symbol is "++". It doesn't match against
".", so we have an error. Normally, we would do things described above, but here we have backtracking.
We don't print any errors, don't discard input, we just restore the state and try to apply "G".
We could also store the info about the error that accured when trying to apply "M.". If non of the productions 
can be applied, we can use this info to report what symbols where expected by parser(As usual, actually).



-Storing the state

There seem to be two ways to store the state when we need to do bactracking. 
The first one would be making a copy of the state of a lexer and buffer. 
Then, if a production fails, we can restore the state.

The second one, the one we're going to use implies having a buffer of tokens we got after we started parsing a production. 
If we encounter an error, we can just set the lookahead token to the first one in the buffer and try applying other production.
I prefer this one because.. it's better. Obviously. You don't have to copy anything. It's faster and it's simpler.

A symbol that needs bactracking when parsing it, may produce symbol that also needs bactracking, so we must be able to 
store several states, which i am going to implement using stack.

Example: Construction of Syntax tree.
Left-factoring & Left recursion.




